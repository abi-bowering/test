{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad608a4f-d313-4b6f-94e2-cdbf030af757",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Here is where we import all the packages we need. Noteably, NumPy is a standard computing package, Pandas is for data manipulation, and Torch is the Python machine learning package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d9f9b7b-c156-4c71-9f07-b4c6d4fb23ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from math import *\n",
    "import copy\n",
    "from scipy.integrate import odeint\n",
    "from matplotlib.lines import Line2D\n",
    "from tabulate import tabulate\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from math import *\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\") \n",
    "#this line says that if we have a GPU, it will do the computations there.\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68cabdf-0b26-4d00-a7c1-a9418e562b74",
   "metadata": {},
   "source": [
    "### Formatting .csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ef513b1-1c61-40c9-8046-4859830c8abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21.5799    21.54    21.44  21.5799.1    21.51    21.42  21.4799    21.34  \\\n",
      "0    21.51  21.3199  21.2399    21.3700  21.4699  21.3899  21.1800  21.2099   \n",
      "1    28.69  28.4799  28.4099    28.5699  28.6599  28.5599  28.3199  28.2900   \n",
      "2    21.11  20.9599  21.0400    21.0400  21.0799  20.9899  20.8700  20.8099   \n",
      "3    21.12  21.0300  21.1200    21.0599  21.1000  20.9500  20.9599  20.8700   \n",
      "4    21.17  21.1800  21.1900    21.1599  21.3400  21.1499  21.1200  20.9599   \n",
      "\n",
      "     21.43    21.35  ...  21.2299  21.2199    21.26    21.25  21.2099  \\\n",
      "0  21.2099  21.2900  ...  21.1399  21.1200  21.2099  21.1499  21.0900   \n",
      "1  28.3999  28.3500  ...  28.0799  28.2399  28.3999  28.2299  28.0900   \n",
      "2  20.9099  20.7600  ...  20.3799  20.7099  20.9400  20.7000  20.4899   \n",
      "3  20.9400  20.8299  ...  20.5000  20.7199  20.9899  20.7500  20.6399   \n",
      "4  20.9400  20.9400  ...  20.7500  20.7800  21.0799  20.8700  20.9400   \n",
      "\n",
      "   21.25.1     21.2  21.5499  21.42.1  21.35.1  \n",
      "0  21.1299  21.0900  21.3700  21.2800  21.1700  \n",
      "1  28.1700  28.2000  28.3799  28.3899  28.3600  \n",
      "2  20.6100  20.7099  20.6800  20.8299  21.0300  \n",
      "3  20.6900  20.7500  20.7900  20.8700  20.8299  \n",
      "4  20.8400  20.8199  21.0000  21.0000  20.9400  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#upload .csv file and skip 13 header rows\n",
    "DTS_calib = pd.read_csv('00 to 23 31Jan2020 copy.csv',skiprows=range(13))\n",
    "#stop after 100 depths (for this early version)\n",
    "DTS_calib = DTS_calib.head(100)\n",
    "#remove column of depths\n",
    "DTS_calib = DTS_calib.iloc[:,1:]\n",
    "\n",
    "#check to see the rows and columns have been skipped\n",
    "print(DTS_calib.head())\n",
    "\n",
    "#create new file which stores the updated version (without headers or depth)\n",
    "DTS_calib.to_csv('00 to 23 31Jan2020 no header top 100.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ca9498f-3ed4-42d5-b663-c8f86b8c0715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23.]\n"
     ]
    }
   ],
   "source": [
    "#convert the DataFrame which we created using Pandas from .csv file into a NumPy array\n",
    "observed_temp = DTS_calib.to_numpy()\n",
    "\n",
    "#Define the dimensions of the array\n",
    "num_depths, num_hours = observed_temp.shape\n",
    "\n",
    "#define a time vector (to be used in later versions to compute splines, this is currently arbitrary)\n",
    "t = np.linspace(0, 23, num = 24)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39466f8-22a1-435e-a0a9-1b62b31cda91",
   "metadata": {},
   "source": [
    "### Spline approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3f8803c-f891-464b-aa7f-0bb2b9bd37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize arrays to store the spline-smoothed data and derivatives\n",
    "smoothed_observed_temp = np.zeros(observed_temp.shape)\n",
    "spline_deriv=np.zeros(observed_temp.shape)\n",
    "\n",
    "# Loop through each row (depth) and fit a spline to smooth the temperature data\n",
    "for i in range(observed_temp.shape[0]):\n",
    "    # Fit a spline to the data for each row (depth)\n",
    "    spline = UnivariateSpline(t, observed_temp[i, :], s=0.08)\n",
    "\n",
    "    # Evaluate the spline at each hour to get the smoothed temperature data\n",
    "    smoothed_observed_temp[i, :] = spline(t)\n",
    "\n",
    "    # Calculate the spline derivative at each hour for the given row (depth)\n",
    "    spline_deriv[i, :] = spline.derivative()(t)\n",
    "\n",
    "##Plot the smoothed temp curve and the spline derivatives!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c8d10c-9fbc-461c-985e-06ffec104329",
   "metadata": {},
   "source": [
    "### Difference quotients to get derivative approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca2a6948-9e7e-43d7-ba05-a3b9f6d2b493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[[-0.27981015  0.05272412  0.12292976 ...  0.07957745  0.1018994\n",
      "  -0.1760312 ]\n",
      " [-0.31483118  0.08191411  0.15308918 ...  0.10629303  0.06108875\n",
      "  -0.04475161]\n",
      " [ 0.01107166 -0.01170817 -0.02708155 ...  0.11057456  0.13815104\n",
      "   0.13818584]\n",
      " ...\n",
      " [ 0.07013962  0.02320785  0.03510411 ...  0.00053649  0.01672686\n",
      "   0.03811482]\n",
      " [ 0.06260708  0.03455807  0.04193977 ... -0.0048157   0.00271191\n",
      "   0.01316791]\n",
      " [ 0.06027059  0.03243285  0.05230167 ...  0.00321359  0.01505309\n",
      "   0.03066906]]\n"
     ]
    }
   ],
   "source": [
    "#define the time step size (delta_t)\n",
    "delta_t=[]\n",
    "for i in range(len(t) -1):\n",
    "    diff = t[i+1] - t[i]\n",
    "    delta_t.append(diff)\n",
    "\n",
    "print(delta_t)\n",
    "\n",
    "#initialize array to store the difference quotients \n",
    "diff_quots=np.zeros((num_depths, num_hours-1))\n",
    "    \n",
    "#compute difference quotient for each row (because we want the difference quotient hour to hour)\n",
    "#using smothed_observed_data because the purpose of the spline approximation is to get better difference quotients\n",
    "for i in range(num_depths):\n",
    "    for j in range(num_hours - 1):\n",
    "        diff_quots[i,j] = (smoothed_observed_temp[i, j+1] - smoothed_observed_temp[i,j])/delta_t[j]\n",
    "        \n",
    "print(diff_quots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c839a-6297-4a26-a4bc-9a6665e01b14",
   "metadata": {},
   "source": [
    "### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae0d4b1-48fc-4712-85fd-1ebc1260ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function # import Function to create custom activations\n",
    "from torch.nn.parameter import Parameter # import Parameter to create custom activations with learnable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e59cbd04-e2cd-4514-a457-c6893b2a3dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this block is neural network specific things we want to load in order to build and train the model\n",
    "\n",
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.x = inputs\n",
    "        self.y = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.x[idx, :]\n",
    "        targets = self.y[idx, :]\n",
    "\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c473de83-ac5b-4c1d-bd3c-ff2a60eab437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (linear1): Linear(in_features=1, out_features=10, bias=True)\n",
      "  (linear2): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (linear3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (linear4): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (linear5): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (linear6): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (linear7): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (linear8): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (mylrelu): LeakyReLU(negative_slope=0.01)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#here we define a few hyperparameters\n",
    "epochs = 200\n",
    "batch_size = 100\n",
    "input_size = 1 #we give the net as input the temperature at a fixed time and depth\n",
    "hidden_size1 = 10\n",
    "hidden_size2 = 20\n",
    "output_size = 1 #the net outputs the T' for the given T. This gives one equation for all depths\n",
    "\n",
    "#to have one equation per depth, the network should have input 100\n",
    "# and output 100 where 100 = number of depths at a fixed time (this is for a later version)\n",
    "\n",
    "class Net(nn.Module) :\n",
    "\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_size,   hidden_size1, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size1, hidden_size2, bias=True)\n",
    "        self.linear3 = torch.nn.Linear(hidden_size2, hidden_size2, bias=True)\n",
    "        self.linear4 = torch.nn.Linear(hidden_size2, hidden_size2, bias=True)\n",
    "        self.linear5 = torch.nn.Linear(hidden_size2, hidden_size2, bias=True)\n",
    "        self.linear6 = torch.nn.Linear(hidden_size2, hidden_size2, bias=True)\n",
    "        self.linear7 = torch.nn.Linear(hidden_size2, hidden_size2, bias=True)\n",
    "        self.linear8 = torch.nn.Linear(hidden_size2, output_size,  bias=True)\n",
    "\n",
    "        self.mylrelu = torch.nn.LeakyReLU()    #Two_corners_LReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.mylrelu(self.linear1(x))\n",
    "        x = self.mylrelu(self.linear2(x))\n",
    "        x = self.mylrelu(self.linear3(x))\n",
    "        x = self.mylrelu(self.linear4(x))\n",
    "        x = self.mylrelu(self.linear5(x))\n",
    "        x = self.mylrelu(self.linear6(x))\n",
    "        x = self.mylrelu(self.linear7(x))\n",
    "        x = self.linear8(x)\n",
    "        return x\n",
    "        \n",
    "#name our network net\n",
    "net = Net(input_size, hidden_size1, hidden_size2, output_size).to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e73c31-f666-4aac-b2ef-af1c469602af",
   "metadata": {},
   "source": [
    "### Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06c1f4fb-0ffa-4824-824d-2bbfec12f917",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (100x24 and 1x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_data, targets \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     28\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m input_data\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m#or use batch size instead of -1 but add , drop_last=True in DataLoader\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m     lo \u001b[38;5;241m=\u001b[39m loss(preds, targets)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[40], line 28\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 28\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmylrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmylrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(x))\n\u001b[1;32m     30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmylrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear3(x))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x24 and 1x10)"
     ]
    }
   ],
   "source": [
    "#define our inputs and targets for the training data\n",
    "train_data = torch.from_numpy(observed_temp)\n",
    "train_expected = torch.from_numpy(diff_quots)\n",
    "\n",
    "#define dataset to use when training\n",
    "dataset = LoadDataset(train_data, train_expected)\n",
    "\n",
    "# This loads data in batches which you can now change to be more than 1 without errors\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#we use Adam as the optimizer, an automatic stochastic gradient descent algorithm\n",
    "#we can tune the hyperparameters if desired\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-03, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "#define the loss function, in our case, mean squared error\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "#initialize an empty list of losses, loss starts at 0.\n",
    "train_loss = 0\n",
    "l2_loss_list = []\n",
    "net.train()\n",
    "for epoch in range(epochs): \n",
    "    # if epoch % 10 == 0:\n",
    "    #     for param_group in optimizer.param_groups:\n",
    "    #         param_group['lr'] /= 2.\n",
    "\n",
    "    batch_idx = 0\n",
    "    for input_data, targets in dataloader:\n",
    "        input_data = input_data.to(device) #or use batch size instead of -1 but add , drop_last=True in DataLoader\n",
    "        preds = net(input_data)\n",
    "        targets = targets.to(device)\n",
    "        lo = loss(preds, targets)\n",
    "        train_loss += lo.detach().numpy()        \n",
    "        optimizer.zero_grad()\n",
    "        lo.backward()\n",
    "        optimizer.step()\n",
    "        batch_idx += 1\n",
    "        \n",
    "    l2_loss_list.append(train_loss/batch_idx)\n",
    "    if epoch%1 ==0:\n",
    "        print('Train Loss = ', l2_loss_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc967fa2-dc90-4e77-8b3e-b4d5237e0335",
   "metadata": {},
   "source": [
    "### Visualizing output\n",
    "\n",
    "Differential equation reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fd7e5ad-d58e-4a28-94c0-da143c3f99b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_cond' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#loop set up to iterate i from 0 to (n_initial_cond-1). \u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#This means that the loop will run 100 times in this case since n_initial_cond is 100.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_initial_cond): \u001b[38;5;66;03m#number of inputs\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Bundle initial conditions for ODE solver\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     y0 \u001b[38;5;241m=\u001b[39m \u001b[43min_cond\u001b[49m[:, i]\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Call the ODE solver\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     psoln \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(odeint(f_net, y0, t))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'in_cond' is not defined"
     ]
    }
   ],
   "source": [
    "# Initial values, each column is a vector x0 of initial conditions\n",
    "components = 1 #means each observation (vector) has one component, ie only one variable is being modelled (temperature)\n",
    "n_initial_cond = 100 #100 initial conditions for each component - 100 depths\n",
    "\n",
    "\n",
    "#compute solution\n",
    "time_steps_sol = len(t) #stores the number of time steps in the solution\n",
    "\n",
    "#initialize 3D array of zeroes to store the true solutions to the ODE system for different initial conditions and time steps\n",
    "true_solut = np.zeros((n_initial_cond,components,time_steps_sol))\n",
    "\n",
    "#initialize 3D array of zeroes to store the network solutions to the ODE system for different initial conditions and time steps\n",
    "net_solut = np.zeros((n_initial_cond,components,time_steps_sol))\n",
    "\n",
    "\n",
    "#loop set up to iterate i from 0 to (n_initial_cond-1). \n",
    "#This means that the loop will run 100 times in this case since n_initial_cond is 100.\n",
    "\n",
    "for i in range(n_initial_cond): #number of inputs\n",
    "    # Bundle initial conditions for ODE solver\n",
    "    y0 = in_cond[:, i]\n",
    "    # Call the ODE solver\n",
    "    psoln = np.transpose(odeint(f_net, y0, t))\n",
    "    net_solut[i,:,:] = psoln\n",
    "net_solut = net_solut.reshape(n_initial_cond,time_steps_sol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
